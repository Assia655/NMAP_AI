import re
import numpy as np
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

try:
    import spacy
    nlp = spacy.load("fr_core_news_sm")
    print("‚úÖ spaCy mod√®le fran√ßais charg√©")
except:
    print("‚ö†Ô∏è  spaCy non install√©. Ex√©cute:")
    print("    pip install spacy")
    print("    python -m spacy download fr_core_news_sm")


class NMAPEmbeddingAgent:
    """
    Agent NMAP avec embeddings spaCy.
    Simple, rapide, et 100% fiable.
    """
    
    def __init__(self, corpus_file: str = "nmap_domain.txt"):
        """Initialiser l'agent"""
        
        self.corpus_file = corpus_file
        self.corpus_documents = []
        
        # Mots clairement hors contexte
        self.out_of_context_words = {
            'document', 'fichier', 'pdf', 'word', 'excel', 'video', 'image',
            'photo', 'music', 'email', 'movie', 'book', 'car', 'house', 'sport',
            'play', 'game', 'film', 'audio', 'sound', 'voice', 'speech',
            'lire', 'regarder', 'livre', 'ouvrir', 'musique', 'vid√©o',
            'cin√©ma', 's√©rie', 'podcast', 'streaming', 'jouer', 'gamer',
            'console', 'jeux', 'imprimante', 'passeport'
        }
        
        # Mots-cl√©s NMAP
        self.nmap_keywords = {
            'scan', 'port', 'host', 'service', 'version', 'os', 'detect',
            'discover', 'enumerate', 'script', 'nse', 'map', 'network', 'probe',
            'syn', 'tcp', 'udp', 'icmp', 'ping', 'trace', 'route', 'firewall',
            'vulnerability', 'exploit', 'cve', 'banner', 'target', 'machine',
            'address', 'ip', 'subnet', 'cidr', 'ipv6', 'timing', 'aggressive',
            'stealth', 'evade', 'bypass', 'fragment', 'xml', 'audit',
            'reconnaissance', 'enumeration', 'topologie', 'infrastructure'
        }
        
        print("üîÑ Initialisation de l'agent NMAP avec spaCy...")
        self._load_corpus()
        self._compute_nmap_embedding()
        print("‚úÖ Agent pr√™t!\n")
    
    def _load_corpus(self):
        """Charger le corpus"""
        try:
            with open(self.corpus_file, 'r', encoding='utf-8') as f:
                self.corpus_documents = [
                    line.strip() for line in f 
                    if line.strip() and not line.startswith('#')
                ]
            print(f"‚úÖ Corpus charg√©: {len(self.corpus_documents)} documents")
        except FileNotFoundError:
            print(f"‚ùå Fichier '{self.corpus_file}' non trouv√©!")
            raise
    
    def _compute_nmap_embedding(self):
        """Calculer l'embedding repr√©sentant le domaine NMAP"""
        print("üßÆ Calcul de l'embedding NMAP...")
        
        nmap_docs = []
        for doc_text in self.corpus_documents[:50]:  # Utiliser les 50 premiers
            doc = nlp(doc_text)
            if doc.has_vector:
                nmap_docs.append(doc.vector)
        
        if nmap_docs:
            self.nmap_embedding = np.mean(nmap_docs, axis=0)
        else:
            self.nmap_embedding = np.zeros(96)  # Dimension par d√©faut spaCy FR
        
        print(f"‚úÖ Embedding NMAP calcul√© (dimension: {len(self.nmap_embedding)})")
    
    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculer la similarit√© cosinus"""
        if len(vec1) == 0 or len(vec2) == 0:
            return 0.0
        
        # √âviter les vecteurs nuls
        if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
            return 0.0
        
        dot_product = np.dot(vec1, vec2)
        norm_vec1 = np.linalg.norm(vec1)
        norm_vec2 = np.linalg.norm(vec2)
        
        return float(dot_product / (norm_vec1 * norm_vec2))
    
    def analyze_query(self, query: str) -> Dict:
        """Analyser une query avec spaCy embeddings"""
        
        # Parser la query avec spaCy
        doc = nlp(query.lower())
        
        if not doc.has_vector:
            return {
                'tokens': [token.text for token in doc],
                'avg_similarity': 0.0,
                'nmap_keywords_found': [],
                'out_of_context': [],
                'query_length': len(doc)
            }
        
        # Similarit√© globale
        avg_similarity = self.cosine_similarity(doc.vector, self.nmap_embedding)
        
        # Mots NMAP et hors contexte
        nmap_keywords_found = []
        out_of_context = []
        
        for token in doc:
            word = token.text.lower()
            if word in self.nmap_keywords:
                nmap_keywords_found.append(word)
            if word in self.out_of_context_words:
                out_of_context.append(word)
        
        return {
            'tokens': [token.text for token in doc],
            'avg_similarity': float(avg_similarity),
            'nmap_keywords_found': nmap_keywords_found,
            'out_of_context': out_of_context,
            'query_length': len(doc)
        }
    
    def understand_query(self, query: str) -> Dict:
        """Comprendre si la query est li√©e √† NMAP"""
        
        analysis = self.analyze_query(query)
        
        avg_similarity = analysis['avg_similarity']
        nmap_keywords_count = len(analysis['nmap_keywords_found'])
        out_of_context_count = len(analysis['out_of_context'])
        query_length = analysis['query_length']
        
        # ============ LOGIQUE DE D√âCISION ============
        
        # Cas 1: Similarit√© tr√®s √©lev√©e ‚Üí NMAP
        if avg_similarity > 0.50:
            is_relevant = True
            reason = f"Embedding similarity tr√®s √©lev√©e ({avg_similarity:.2f})"
        
        # Cas 2: Similarit√© bonne + keywords NMAP ‚Üí NMAP
        elif avg_similarity > 0.40 and nmap_keywords_count >= 1:
            is_relevant = True
            reason = f"Bonne similarit√© ({avg_similarity:.2f}) + keywords NMAP"
        
        # Cas 3: Similarit√© faible + mots hors contexte ‚Üí NON-NMAP
        elif avg_similarity < 0.35 and out_of_context_count >= 2:
            is_relevant = False
            reason = f"Faible similarit√© ({avg_similarity:.2f}) + mots hors contexte"
        
        # Cas 4: Similarit√© moyenne + keywords NMAP ‚Üí NMAP
        elif avg_similarity > 0.30 and nmap_keywords_count >= 2:
            is_relevant = True
            reason = f"Similarit√© OK ({avg_similarity:.2f}) + multiple keywords NMAP"
        
        # Cas 5: Requ√™te longue avec bonne similarit√© ‚Üí NMAP
        elif query_length > 15 and avg_similarity > 0.35:
            is_relevant = True
            reason = f"Requ√™te longue ({query_length} mots) + similarit√© ({avg_similarity:.2f})"
        
        # Cas 6: Par d√©faut ‚Üí NON-NMAP
        else:
            is_relevant = False
            reason = f"Similarit√© insuffisante ({avg_similarity:.2f})"
        
        # ============ CONFIANCE ============
        
        if is_relevant:
            if avg_similarity > 0.55:
                confidence = "üü¢ TR√àS HAUTE"
            elif avg_similarity > 0.40:
                confidence = "üü° MOYENNE-HAUTE"
            else:
                confidence = "üü° MOYENNE"
        else:
            confidence = "üî¥ BASSE"
        
        return {
            'query': query,
            'is_relevant': is_relevant,
            'decision': '‚úÖ ACCEPT√âE - NMAP' if is_relevant else '‚ùå REJET√âE - Contexte non-NMAP',
            'analysis': {
                'tokens': analysis['tokens'],
                'nmap_keywords_found': analysis['nmap_keywords_found'],
                'out_of_context': analysis['out_of_context'],
                'query_length': analysis['query_length']
            },
            'scores': {
                'embedding_similarity': round(avg_similarity, 3),
                'nmap_keywords_count': nmap_keywords_count,
                'out_of_context_count': out_of_context_count,
                'decision_reasoning': reason
            },
            'confidence': confidence
        }


# ============ TESTS ============

if __name__ == "__main__":
    print("=" * 100)
    print("üöÄ AGENT NMAP AVEC SPACY EMBEDDINGS - TESTS")
    print("=" * 100)
    
    try:
        agent = NMAPEmbeddingAgent("nmap_domain.txt")
        
        test_cases = [
            # ‚úÖ NMAP
            ("scanner le port 80", True),
        ]
        
        print("\n")
        correct = 0
        for query, expected in test_cases:
            result = agent.understand_query(query)
            is_correct = result['is_relevant'] == expected
            correct += is_correct
            
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"{status} {result['decision']}")
            print(f"   Query: \"{query[:60]}...\" " if len(query) > 60 else f"   Query: \"{query}\"")
            print(f"   Similarity: {result['scores']['embedding_similarity']}")
            print(f"   Confiance: {result['confidence']}\n")
        
        print("=" * 100)
        print(f"‚úÖ R√©sultat: {correct}/{len(test_cases)} tests pass√©s ({100*correct//len(test_cases)}%)")
        print("=" * 100)
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        print("\nPour r√©soudre, ex√©cute:")
        print("  pip install spacy")
        print("  python -m spacy download fr_core_news_sm")